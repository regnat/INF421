\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}

\usepackage[frenchb]{babel}

%opening
\title{Projet INF421 \\ À la recherche de clés secrètes vulnérables}
\author{\bsc{Hétier} Guillaume, \bsc{Hufschmitt} Théophane}

\begin{document}

\maketitle

\section{Mise en place~: une implémentation jouet de RSA}
En factorisant à l'aide d'un logiciel de calcul formel la clé \texttt{minisecret.pub}, on arrive à retrouver le contenu du fichier \texttt{minisecret.txt}, en utlisant openssh pour générer la clef priver et déchiffrer le fichier.


\section{Recherche naïve~: algorithme d'Euclide et exploration paire par paire}
Une simple boucle sur tous les couples de clés permet de retrouver l'ensemble des clés vulnérables, et pour chacune un de leurs coefficients, ce qui nécessite un calcul de $\frac{n(n-1)}{2}$ pgcds (soit une complexité quadratique en le nombre de clés).

  Deux calculs sur cinq cent et mille clés nécessitent respectivement 11 et 41 secondes, ce qui confirme la complexité quadratique.
  
  
\section{Arbres des produits et des restes}

  \subsection{Arbre des produits}
  \subsubsection{Construction de l'arbre des produits}
  On construit l'arbre à partir des feuilles de manière simple en utilisant une file. On insère les feuilles dans cette dernière, et tant qu'elle contient plus d'un élément, on retire les deux éléments en têtes, on les réunit dans un même sous-arbre que l'on ajoute à la file.
  L'algorithme termine bien puisque le nombre d'éléments dans la pile diminue strictement à chaque itération. Il est juste grâce à l'invariant~: à tout instant, la file ne contient que des arbres produits dont les feuilles sont les éléments initiaux.
  
  \subsubsection{Complexité de la construction de l'arbre des produits\label{sn:complexite_arb_prod}}
  Nous avons en entrée $N$ clés, ayant au plus $m$ chiffres.
  On ne calculera la complexité qu'en nombre de multiplications, cette opération étant la plus représentative de la construction de l'arbre des produits.
  Supposons que le nombre $N$ de clés en entrée est de la forme $2^k$, avec $k\in\mathbf{N}$.
  
  Notons $C(N,m)$ la complexité de la construction de l'arbre, et $CM(m)$ la complexité de la multiplication de deux nombres de $m$ chiffres.
  
  À chaque étage de l'arbre à l'exception des feuilles, on va réaliser autant de multiplication que nœuds présents à cet étage, soit $2^{k-i}$ pour l'étage $i$, ou l'étage $0$ représente les feuilles.
  
  De plus, le produit de deux nombres a au plus pour nombre de chiffre la somme des chiffres de ses facteurs.
  Les nombres de l'étage $i$ ont donc au plus $2^{i-1}m$ chiffres, par une récurrence immédiate.
  Les $2^{k-i}$ multiplications de de l'étage $i$ ont donc une complexité en $CM(2^{i-1}m)$.
  
  D'où une complexité totale~: $C(2^k,m) = \sum_{i=1}^k 2^{k-i}CM(2^{i-1}m)$.
  
  Donc si $CM(m) = O(m^2)$~:
  \begin{eqnarray*}
   C(2^k,m) &=& \sum_{i=1}^k 2^{k-i}O({(2^{i-1}m)}^2)\\
   &=& O(2^{k-2}m^2\sum_{i=1}^k 2^i)\\
   &=& O(2^k m^2 2^k)\\
   &=& O(2^{2k} m^2)
  \end{eqnarray*}
  
  D'où $C(N,m) = O(N^2m^2)$, ce qui se prolonge pour toute valeur de $N$, puisque le cas d'un arbre complet est celui pour lequel le plus de multiplications sont nécessaires.
  
  Dans le cas où $CM(m) = O(m\log(m)\log(\log(m)))$, les calculs du~\ref{sn:complexite_arb_prod} deviennent~:
  \begin{eqnarray*}
   C(2^k,m) &=& \sum_{i=1}^k 2^{k-i}O(2^{i-1}m\log(2^{i-1}m)\log(\log(2^{i-1}m)))\\
   C(2k,m) &\leq& \alpha(m2^{k-1}\sum_{i=1}^k(\log(m)+i-1)\log(\log(m)+i-1))\\
   &\leq& \alpha 2^k m \log(\log(m)+k)(k \log(m) + \frac{k-1}{2}*k)\\
   &\leq& \alpha 2^k m \log(\log(m)+k)(k\log(m)+k^2)
  \end{eqnarray*}
  
  D'où $C(N) = O(Nm\log(N)\log(Nm)\log(\log(Nm)))$.
  
  Cette complexité est bien inférieure à la précédente, puisque un facteur $Nm$ est remplacé par une expression à base de logarithmes~: $\log(N)\log(Nm)\log(\log(Nm))$.

  \subsection{Arbre des restes}
  \subsubsection{Construction de l'arbre des restes}
  On construit alors l'arbre des restes (on peut décider de ne construire que ses feuilles, nous avons implémenté les deux versions) en faisant un parcours en profondeur de l'arbre des produit et en calculant le reste à chaque étape.
  
  \subsubsection{Complexité de la construction de l'arbre des restes\label{sn:complexite_arb_rst}}
  On reprends les même notations que précédemment et on suppose à nouveaux que $N$ est de la forme $2^k$, avec $k\in\mathbf{N}$.
  On observe tout d'abord que pour la construction de l'arbre des restes, on fait une division euclidienne par nœud de l'arbre, ainsi qu'une multiplication (qu'on néglige dans le calcul de la complexité, puisque cela revient à modifier la constante devant la complexité de la division) pour obtenir le diviseur. Celui-ci est le carré d'un nombre de l'étage $i$ de l'arbre des produits si on est en train de construire l'étage $i$ de l'arbre des restes, il a donc au plus $2 \times 2^{i-1}m$ chiffres. Les restes de l'étage $i$ ont donc au plus $2^i m$ chiffres.
  Lors du calcul d'un reste de l'étage $i$, on divise donc un nombre d'au plus $2^{i+1}m$ chiffre par un nombre en ayant au plus $2^i m$, ce qui se fait donc en complexité $CD(2^{i+1}m)$, et il y a $2^{k-i}$ divisions à faire par étage.
  
  D'où une complexité totale~: $C(2^k, m) = \sum_{i=0}^{k-1}2^{k-i}CD(2^{i+1}m)$.
  
  On retrouve à une constante près l'expression obtenue pour le calcul de la complexité de la construction de l'arbre des produits, le résultat est donc identique.
  On a donc~:
  
  Pour $CD(m) = O(m^2)$
  \[
   C(N,m) = O(N^2m^2)
  \]
  
  Pour $CD(m) = O(m\log(m)\log(\log(m)))$
  \[
   C(N) = O(Nm\log(N)\log(Nm)\log(\log(Nm)))
  \]
  
  Comme précédemment, on observe une nette baisse de la compexité.
  
  \subsection{Preuve de l'algorithme}
  Nous allons maintenant prouver l'algorithme, afin de montrer qu'il nous permet bien de trouver des facteurs communs.
  Ceci va nous permettre de mettre en évidence l'une de ses limitations, qui empêche de factoriser immédiatement certaines clés.
  
  Nous appellerons ici $r_i$ une feuille de l'arbre des restes, $p_i$ la feuille correspondante de l'arbre des produits, et $S$ le produit de toutes les clés, c'est à dire la racine de l'arbre des produits.
  Par construction de l'arbre des restes, on a donc~: $r_i = S \mod pi^2$.
  
  Montrons tout d'abord qu'un diviseur premier de $x~:= pgcd(r_i/p_i,p_i)$ est toujours un facteur commun entre $y$ et une autre clé, si $r_i$ est non nul. Par définition de $r_i$, $p_i^2$ ne divise pas $r_i$ et donc $p_i$ divise ne divise pas $r_i/p_i$. Donc un diviseur du pgcd $x$, s'il est strictement supérieur à $1$, ne peut provenir que d'un autre facteur de $S$ que $p_i$. Mais il divise aussi $p_i$, c'est donc bien un facteur commun.
  
  Montrons maintenant que si $p_i$ a un facteur en commun avec une autre clef, alors ce facteur divise $x$. Notons $y$ ce facteur commun. On peut donc écrire $S$ sous la forme $S = y^2*P$. Donc, $y^2$ divise $S$ et $p_i^2$, donc $r_i$.
  Donc $y$ divise $p_i$ et $r_i/p_i$ ($p_i$ est différent de $y^2$ pour une clef RSA), c'est donc un diviseur commun.
  Supposons qu'il ne divise pas le pgcd. Il existe donc un autre facteur commun entre $p_i$ et une autre clé, et on a donc trouvé la factorisation de $p_i$. Mais alors, $S$ est un multiple de $p_i^2$, donc $r_i$ est nul et $x = p_i$, ce qui est absurde, puisque on n'avait supposé le contraire. Donc $y$ divise bien $x$.
  
  On a donc justifié l'algorithme dans le sens ou on a montré les diviseurs premiers du pgcd sont exactement les facteurs communs entre $p_i$ les autres clés. Si pgcd est égal à $1$ ou est premier, on peut donc conclure~: soit il n'y a pas de facteur commun, soit on récupère la factorisation de $p_i$ à partir du facteur obtenu. Mais si le pgcd n'est pas premier (et est donc égal à $p_i$), on en revient au problème initial.
  
   \subsection{Le \og{}cas des zéros\fg}
  
   Ce problème se rencontre quand les deux facteurs de $p_i$ sont partagés avec d'autres clés. On a alors $p_i^2 | S$, et donc $r_i = 0$. Deux cas peuvent se présenter~: soit on a un \og{} cycle \fg{} de clés partageant des facteur, du type $ab - bc - ca$ et on ne peut alors récupérer aucune information sur les facteurs de ces clés, soit on a simplement une \og{} chaine \fg, du type $ab - bc - cd$. Dans ce cas, on peut récupérer tout les facteurs premiers, mais on ne connaitra pas la décomposition de $bc$, qu'il faudra déterminer ensuite.
  
  Pour factoriser ces clés, qui partagent des facteurs communs mais ne sont pas factorisable par l'algorithme de l'arbre des restes, nous calculons donc l'ensemble des pgcd entre les clés ayant données un reste nul et les clefs dont le pgcd était différent de $1$ (et qui ont donc un facteur commun). Cette méthode a une complexité quadratique en le nombre de clef dans le pire des cas, ou toutes les clés feraient partie de cycle. En pratique, étant donné le faible nombre de clés présentes dans des cycles, cette méthode reste efficace.
  
  \section{Oraganisation et implémentation du déchiffrement}
  Nous avons utilisé plusieurs classes afin d'organiser et cloisonner correctement notre code. Nous allons ici faire un rapide résumé de leur organisation. Plus de détails sur leur contenu peuvent être trouvé à travers les commentaires présent dans le code et dans la documentation jointe.
  
  Tout d'abord, une première classe est chargée de parser le fichier contenant les clés qui seront alors stockée dans une LinkedList.
  On va alors pouvoir faire appel à la fonction de recherche des facteur commun (présente, avec ses dépendances, dans la classe FindWeakKeysByProductTree). Elle va construire l'arbre des produits, puis l'arbre des restes (on ne construira en fait que les feuilles de ce dernier, les valeurs des noeuds n'étant pas utiles), à l'aide de la classe ProductTree. Puis on va rechercher les facteurs communs, tout d'abord grace à l'algorithme présenté par le sujet, puis, pour les clefs présentant un reste nul, en calculant leur pgcd avec toutes les clés partageant des facteurs (c'est à dire toutes les clefs pour lesquelles on a pas trouvé un pgcd de 1 lors de l'algorithme précédent.)
  Cette étape peut, dans le pire des cas, présenter une complexité quadratique, mais elle n'est pas un problème en pratique, étant donné le faible nombre de clés ayant des facteurs communs.
  Enfin, les clefs et leurs facteurs sont écrits dans un fichier \texttt{weakKeys.txt}.
  
  La classe genKeys va alors prendre ce fichier en entré et générer l'ensemble des clés privées (un fichier par clef).
  
  Une boucle en shell (fichier \texttt{testKeys.sh}) permet ensuite de tester toutes les clés sur le fichier \texttt{bigsecret.txt} avec l'utilitaire openssh. On obtient ainsi le contenu du fichier \texttt{bigsecret.txt} («~Ouf~! fit-il, suant, las, mais satisfait, j'ai cru un instant n'y jamais aboutir.~»).

\section{Multiplication et pgcd rapides}
  Nous avons testé notre code avec les versions 1.7 et 1.8 d'OpenJDK, ainsi qu'avec la librairie \texttt{bigint} optimisé proposé par le sujet. Les algorithmes optimisé proposé par cette bibliothèque on en effet été intégré dans OpenJDK8 pour la plupart, à l'exception de deux d'entre eux.
  L'utilisation d'OpenJDK8 rend ainsi l'execution de l'algorithme considérablement plus rapide, et on observe encore un gain de temps non négligeable, comme on peut l'oberver dans le tableau ci-dessous.
  
  \begin{figure}[b]
  \begin{center}
  \begin{tabular}{|c|c|c|c|c|}
   \hline
   Nombre de clés & 100 & 1000 & 10000 & 10000\\
   \hline
   OpenJDK7 & nd & nd & nd & nd\\
   \hline
   OpenJDK8 & nd & nd & nd & nd\\
   \hline
   bigint & nd & nd & nd & nd\\
   \hline
  \end{tabular}
  \caption{Durée d'exécution du programme selon les algorithmes de traitement des big integers utilisés.}
  \end{center}
  \end{figure}




  
\end{document}
